{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Euclidean distance\n",
    "\n",
    "Euclidean distance is the shortest distance between two points in an N dimensional space also known as Euclidean space. It is used as a common metric to measure the similarity between two data points and used in various fields such as geometry, data mining, deep learning and others.\n",
    "\n",
    "It is, also, known as Euclidean norm, Euclidean metric, L2 norm, L2 metric and Pythagorean metric.\n",
    "\n",
    "Consider two points P1 and P2:\n",
    "\n",
    "P1: (X1, Y1)\n",
    "P2: (X2, Y2)\n",
    "\n",
    "Then, the euclidean distance between P1 and P2 is given as:\n",
    "\n",
    "![img](https://i.imgur.com/Sl1vjnQ.png)\n",
    "\n",
    "\n",
    "#### Euclidean distance in N-D space\n",
    "\n",
    "In a N dimensional space, a point is represented as (x1, x2, ..., xN).\n",
    "\n",
    "Consider two points P1 and P2:\n",
    "\n",
    "P1: (X1, X2, ..., XN)\n",
    "P2: (Y1, Y2, ..., YN)\n",
    "\n",
    "Then, the euclidean distance between P1 and P2 is given as:\n",
    "\n",
    "![img](https://i.imgur.com/ixPoojJ.png)\n",
    "\n",
    "Furthermore, we can carry on like this into 4 or more dimensions, in general J dimensions,\n",
    "where J is the number of variables. Although we cannot draw the geometry any more, we\n",
    "can express the distance between two J-dimensional vectors x and y as:\n",
    "\n",
    "![img](https://i.imgur.com/k1matej.png)\n",
    "\n",
    "There are quite a few distance measurement techniques, e.g. few other popular distance measures include:\n",
    "\n",
    "- Hamming Distance: Calculate the distance between binary vectors ([wikipedia](https://en.wikipedia.org/wiki/Hamming_distance)).\n",
    "\n",
    "- Manhattan Distance: Calculate the distance between real vectors using the sum of their absolute difference. Also called City Block Distance ([wikipedia](https://en.wikipedia.org/wiki/Taxicab_geometry)).\n",
    "\n",
    "- Minkowski Distance: Generalization of Euclidean and Manhattan distance ([wikipedia](https://en.wikipedia.org/wiki/Minkowski_distance)).\n",
    "\n",
    "Euclidean is a good distance measure to use if the input variables are similar in type (e.g. all measured widths and heights). Manhattan distance is a good measure to use if the input variables are not similar in type (such as age, gender, height, etc.\n",
    "\n",
    "Manhattan distance is used only if the points are arranged in square format and that too the distance between each of the points should be a multiple of the length of the side of a square. We rarely come across this kind of scenarios in realtime and the mostly used metric is Euclidean distance as we prefer it when working on completely numerical data. When we work on the text data, the cosine distance is an appropriate metric.\n",
    "\n",
    "---\n",
    "\n",
    "## What does it mean to normalize an array ?\n",
    "\n",
    "![img](https://i.imgur.com/DxlL7sm.png)\n",
    "\n",
    "Data normalization is used in machine learning to make model training less sensitive to the scale of features. This allows our model to converge to better weights and, in turn, leads to a more accurate model. Normalization makes the features more consistent with each other, which allows the model to predict outputs more accurately.\n",
    "\n",
    "To normalize a vector in math means to divide each of its elements to some value V so that the length/norm of the resulting vector is 1. Turns out the needed V is equal the length (the length of the vector).\n",
    "\n",
    "![img](https://i.imgur.com/UaayUqF.png)\n",
    "\n",
    "So this is basically the following norm calculations\n",
    "\n",
    "![img](https://i.imgur.com/4kPSrDI.png)\n",
    "\n",
    "For a vector x having N components, the L¹ just adds up the components. Since we would like our magnitude to always be positive, we take the absolute value of the components. The L² norm takes the sum of the squared values, taking the square root at the end.\n",
    "\n",
    "Say you have this array.\n",
    "\n",
    "`[-3, +4]`\n",
    "\n",
    "Its length (in Euclid metric) is: `V = sqrt((-3)^2 + (+4)^2) = 5`\n",
    "\n",
    "So its corresponding normalized vector is:\n",
    "\n",
    "`[-3/5, +4/5]`\n",
    "\n",
    "Its length is now: `sqrt ( (-3/5)^2 + (+4/5)^2 )` which is 1.\n",
    "\n",
    "You can use another metric (e.g. I think Manhattan distance)\n",
    "but the idea is the same. Divide each element of your array\n",
    "by `V` where `V = || your_vector || = norm (your_vector)`.\n",
    "\n",
    "[Read further](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization)\n",
    "\n",
    "While deriving TF-DF, the final TF-IDF metric that we will be using is a normalized version of the tfidf matrix that we get from the product of tf and idf. We will normalize the tfidf matrix by dividing it by the L2 norm of the matrix, also known as the Euclidean norm, which is the square root of the sum of the square of each term’s tfidf weight. Mathematically we can represent the final tfidf feature vector as follows:\n",
    "\n",
    " ### $tfidf= tfidf / || tfidf ||$\n",
    "\n",
    "where ∥tfidf∥ represents the Euclidean L2 norm for the tfidf matrix. There are multiple variants of this model but they all end up with similar results.\n",
    "\n",
    "Informally speaking, the norm is a generalization of the concept of (vector) length; from the [Wikipedia entry][1]:\n",
    "\n",
    "> In linear algebra, functional analysis, and related areas of mathematics, a **norm** is a function that assigns a strictly positive *length* or *size* to each vector in a vector space.\n",
    "\n",
    "The [L2-norm][2] is the usual Euclidean length, i.e. the square root of the sum of the squared vector elements.\n",
    "\n",
    "The [L1-norm][3] is the sum of the absolute values of the vector elements.\n",
    "\n",
    "The [max-norm][4] (sometimes also called infinity norm) is simply the maximum absolute vector element.\n",
    "\n",
    "As the docs say, normalization here means making our vectors (i.e. data samples) having unit length, so specifying *which* length (i.e. which norm) is also required.\n",
    "\n",
    "You can easily verify the above adapting the examples from the [docs][5]:\n",
    "\n",
    "<!-- language-all: lang-python -->\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    import numpy as np\n",
    "\n",
    "    X = [[ 1., -1.,  2.],\n",
    "         [ 2.,  0.,  0.],\n",
    "         [ 0.,  1., -1.]]\n",
    "\n",
    "    X_l1 = preprocessing.normalize(X, norm='l1')\n",
    "    X_l1\n",
    "    # array([[ 0.25, -0.25,  0.5 ],\n",
    "    #        [ 1.  ,  0.  ,  0.  ],\n",
    "    #        [ 0.  ,  0.5 , -0.5 ]])\n",
    "\n",
    "You can verify by simple visual inspection that the absolute values of the elements of `X_l1` sum up to 1.\n",
    "\n",
    "    X_l2 = preprocessing.normalize(X, norm='l2')\n",
    "    X_l2\n",
    "    # array([[ 0.40824829, -0.40824829,  0.81649658],\n",
    "    #        [ 1.        ,  0.        ,  0.        ],\n",
    "    #        [ 0.        ,  0.70710678, -0.70710678]])\n",
    "\n",
    "    np.sqrt(np.sum(X_l2**2, axis=1)) # verify that L2-norm is indeed 1\n",
    "    # array([ 1.,  1.,  1.])\n",
    "\n",
    "\n",
    "  [1]: https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "  [2]: http://mathworld.wolfram.com/L2-Norm.html\n",
    "  [3]: http://mathworld.wolfram.com/L1-Norm.html\n",
    "  [4]: http://mathworld.wolfram.com/L-Infinity-Norm.html\n",
    "  [5]: http://scikit-learn.org/stable/modules/preprocessing.html#normalization\n",
    "\n",
    "---\n",
    "\n",
    "## Normalizing a Vector\n",
    "\n",
    "Mathematically a norm is a total size or length of all vectors in a vector space or matrices. And after we calculate the Norm, then we can normalize a vector. By definition a norm on a vector space—over the real or complex field—is an assignment of a non-negative real number to a vector. The norm of a vector is its length, and the length of a vector must always be positive (or zero). A negative length makes no sense.\n",
    "\n",
    "Taking any vector and reducing its magnitude to 1.0 while keeping its direction is called normalization. Normalization is performed by dividing the x and y (and z in 3D) components of a vector by its magnitude:\n",
    "\n",
    "For any vector V = (x, y, z),\n",
    "\n",
    "we know the magnitude |V| = sqrt(x*x + y*y + z*z) which gives the length of the vector.\n",
    "\n",
    "When we normalize a vector, we actually calculate\n",
    "\n",
    "#### V/|V| = (x/|V|, y/|V|, z/|V|).\n",
    "\n",
    "Lets look at an example\n",
    "\n",
    "![img](https://i.imgur.com/2PCb8nh.png)\n",
    "\n",
    "Can do some basic calculation to see that a normalized vector has length 1. This is because:\n",
    "\n",
    "(In first line below I to bring the sqrt outside of the braces, I am multiplying x/|V| with x/|V| and so on )\n",
    "\n",
    "```\n",
    "| V/|V| | = sqrt((x/|V|)*(x/|V|) + (y/|V|)*(y/|V|) + (z/|V|)*(z/|V|))\n",
    "          = sqrt(x*x + y*y + z*z) / |V|\n",
    "          = |V| / |V|\n",
    "          = 1\n",
    "```\n",
    "\n",
    "Hence, we can call normalized vectors as unit vectors (i.e. vectors with unit length).\n",
    "\n",
    "Any vector, when normalized, only changes its magnitude, not its direction. Also, every vector pointing in the same direction, gets normalized to the same vector (since magnitude and direction uniquely define a vector). Hence, unit vectors are extremely useful for providing directions.\n",
    "\n",
    "\n",
    "A vector of length 1 is called a unit vector. In $R^2$ , the set of all unit vectors can be identified with the unit circle, the circle of radius 1 centered at the origin\n",
    "\n",
    "![img](https://i.imgur.com/buowteZ.png)\n",
    "\n",
    "---\n",
    "\n",
    "### L1 Vs L2? Which one to use?\n",
    "\n",
    "#### L1 norm\n",
    "\n",
    "Is also known as least absolute deviations (LAD), least absolute errors (LAE)\n",
    "It is basically minimizing the sum of the absolute differences (S) between the target value (Yi) and the estimated values (f(xi)): as shown in picture 1\n",
    "On another words Sum of absolute values = 1\n",
    "Example if applied this norm along row then sum of square for a row = 1.\n",
    "It is insensitive to outliers\n",
    "Sparsity:\n",
    "Refers to that only very few entries in a matrix (or vector) is non-zero.\n",
    "L1-norm has the property of producing many coefficients with zero values or very small values with few large coefficients.\n",
    "\n",
    "Having, for example, the vector X = [3,4]:\n",
    "\n",
    "![img](https://i.imgur.com/z4BauDL.png)\n",
    "\n",
    "The L1 norm is calculated by\n",
    "\n",
    "### ||X || = |3| + |4| = 7\n",
    "\n",
    "#### L2 norm\n",
    "\n",
    "It is the shortest distance to go from one point to another., Is also known as least squares\n",
    "\n",
    "Sum of squares = 1\n",
    "\n",
    "Example if applied this norm along row then sum of square for a row = 1.\n",
    "\n",
    "takes outliers in consideration during training:\n",
    "\n",
    "it is resistant to outliers in the data.\n",
    "\n",
    "Computational efficiency:\n",
    "\n",
    "L1-norm does not have an analytical solution, but L2-norm does.\n",
    "\n",
    "This allows the L2-norm solutions to be calculated computationally efficiently.\n",
    "However, L1-norm solutions does have the sparsity properties which allows it to be used along with sparse algorithms, which makes the calculation more computationally efficient.\n",
    "\n",
    "The L1 norm is the sum of the absolute values.\n",
    "\n",
    "The L2 norm is the square root of the sum of the squared values.\n",
    "\n",
    "By squaring values, you are putting more emphasis on large values and less influence on small values.\n",
    "\n",
    "For example, consider just the ten-element vector [1,1,1,1,1,1,1,1,1,10]. The L1 norm is 19; and the largest value, 10, contributes 10/19=53% of it.\n",
    "\n",
    "The L2 norm is sqrt(109)=10.44, and the largest value contributes 100/109=92% of the sum.\n",
    "\n",
    "---\n",
    "\n",
    "## Differences between Norm of a Vector and distance between two points\n",
    "\n",
    "#### Key point to remember - Distance are always between two points and Norm are always for a Vector.\n",
    "\n",
    "#### That means Euclidean Distance between 2 points x1 and x2 is nothing but the L2 norm of vector (x1 - x2)\n",
    "\n",
    "By definition L2 Norm of a vector = Euclidian distance of that point vector from origin.\n",
    "\n",
    "In other words, the distance(metric) between any two vectors can be defined as the norm of the difference those vectors.\n",
    "\n",
    "![img](https://i.imgur.com/cYxlXSv.png)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}